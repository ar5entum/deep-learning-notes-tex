\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\providecommand \oddpage@label [2]{}
\BKM@entry{id=1,open,dest={636861707465722E31},srcline={18}}{5C3337365C3337375C303030315C3030305C3034305C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030745C3030306F5C3030305C3034305C303030645C303030655C303030655C303030705C3030305C3034305C3030306C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\BKM@entry{id=2,open,dest={73656374696F6E2E312E31},srcline={20}}{5C3337365C3337375C303030315C3030302E5C303030315C3030305C3034305C303030415C303030495C3030305C3034305C3030304D5C3030304C5C3030305C3034305C303030445C3030304C}
\BKM@entry{id=3,open,dest={73656374696F6E2E312E32},srcline={28}}{5C3337365C3337375C303030315C3030302E5C303030325C3030305C3034305C303030505C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction to deep learning}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}AI ML DL}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The AI-ML-DL venn diagram}}{1}{figure.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Perceptron}{1}{section.1.2}\protected@file@percent }
\BKM@entry{id=4,open,dest={73756273656374696F6E2E312E322E31},srcline={36}}{5C3337365C3337375C303030315C3030302E5C303030325C3030302E5C303030315C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C3030304C5C303030695C3030306E5C303030655C303030615C303030725C3030305C3034305C303030505C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Limitations of Linear Perceptron}{2}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Non linearities in data}}{2}{figure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Sigmoid activation function}}{3}{figure.1.3}\protected@file@percent }
\BKM@entry{id=5,open,dest={73656374696F6E2E312E33},srcline={130}}{5C3337365C3337375C303030315C3030302E5C303030335C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030585C3030304F5C30303052}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces tanh activation function}}{4}{figure.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces ReLU activation function}}{4}{figure.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Learning XOR}{4}{section.1.3}\protected@file@percent }
\BKM@entry{id=6,open,dest={73656374696F6E2E312E34},srcline={162}}{5C3337365C3337375C303030315C3030302E5C303030345C3030305C3034305C303030495C3030306D5C303030705C3030306C5C303030655C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030615C3030305C3034305C3030306D5C303030755C3030306C5C303030745C303030695C3030302D5C3030306F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030705C303030655C303030725C303030635C303030655C303030705C303030745C303030725C3030306F5C3030306E}
\BKM@entry{id=7,open,dest={73656374696F6E2E312E35},srcline={195}}{5C3337365C3337375C303030315C3030302E5C303030355C3030305C3034305C303030515C303030755C303030615C3030306E5C303030745C303030695C303030665C303030795C303030695C3030306E5C303030675C3030305C3034305C3030304C5C3030306F5C303030735C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Implementation of a multi-output perceptron}{6}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Quantifying Loss}{6}{section.1.5}\protected@file@percent }
\BKM@entry{id=8,open,dest={73656374696F6E2E312E36},srcline={209}}{5C3337365C3337375C303030315C3030302E5C303030365C3030305C3034305C3030304C5C3030306F5C303030735C303030735C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030625C303030795C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\BKM@entry{id=9,open,dest={73756273656374696F6E2E312E362E31},srcline={217}}{5C3337365C3337375C303030315C3030302E5C303030365C3030302E5C303030315C3030305C3034305C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D5C3030305C3034305C303030535C303030745C303030655C303030705C30303073}
\BKM@entry{id=10,open,dest={73756273656374696F6E2E312E362E32},srcline={227}}{5C3337365C3337375C303030315C3030302E5C303030365C3030302E5C303030325C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C303030675C3030305C3034305C303030525C303030615C303030745C30303065}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Loss Optimization by Gradient Descent}{7}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Algorithm Steps}{7}{subsection.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}Learning Rate}{7}{subsection.1.6.2}\protected@file@percent }
\BKM@entry{id=11,open,dest={73756273656374696F6E2E312E362E33},srcline={242}}{5C3337365C3337375C303030315C3030302E5C303030365C3030302E5C303030335C3030305C3034305C303030445C303030655C3030306C5C303030745C303030615C3030305C3034305C303030725C303030755C3030306C5C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.3}Delta rule}{8}{subsection.1.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces An example of a convex and a non convex surface function}}{8}{figure.1.6}\protected@file@percent }
\BKM@entry{id=12,open,dest={73656374696F6E2E312E37},srcline={281}}{5C3337365C3337375C303030315C3030302E5C303030375C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030565C303030615C3030306E5C303030695C303030735C303030685C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030505C303030725C3030306F5C303030625C3030306C5C303030655C3030306D}
\BKM@entry{id=13,open,dest={73756273656374696F6E2E312E372E31},srcline={292}}{5C3337365C3337375C303030315C3030302E5C303030375C3030302E5C303030315C3030305C3034305C303030445C303030655C3030306C5C303030745C303030615C3030305C3034305C303030725C303030755C3030306C5C303030655C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C303030735C303030695C303030675C3030306D5C3030306F5C303030695C303030645C3030305C3034305C303030615C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}The Vanishing Gradient Problem}{9}{section.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Delta rule with sigmoid activation function}{9}{subsection.1.7.1}\protected@file@percent }
\BKM@entry{id=14,open,dest={73656374696F6E2E312E38},srcline={317}}{5C3337365C3337375C303030315C3030302E5C303030385C3030305C3034305C303030425C303030615C303030635C3030306B5C303030705C303030725C3030306F5C303030705C3030306F5C303030675C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=15,open,dest={73756273656374696F6E2E312E382E31},srcline={320}}{5C3337365C3337375C303030315C3030302E5C303030385C3030302E5C303030315C3030305C3034305C303030465C3030306F5C303030725C303030775C303030615C303030725C303030645C3030305C3034305C303030505C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=16,open,dest={73756273656374696F6E2E312E382E32},srcline={324}}{5C3337365C3337375C303030315C3030302E5C303030385C3030302E5C303030325C3030305C3034305C303030425C303030615C303030635C3030306B5C303030775C303030615C303030725C303030645C3030305C3034305C303030505C303030725C3030306F5C303030705C303030615C303030675C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=17,open,dest={73756273656374696F6E2E312E382E33},srcline={328}}{5C3337365C3337375C303030315C3030302E5C303030385C3030302E5C303030335C3030305C3034305C303030555C303030705C303030645C303030615C303030745C303030655C3030305C3034305C303030525C303030755C3030306C5C30303065}
\BKM@entry{id=18,open,dest={73656374696F6E2E312E39},srcline={346}}{5C3337365C3337375C303030315C3030302E5C303030395C3030305C3034305C303030535C303030745C3030306F5C303030635C303030685C303030615C303030735C303030745C303030695C303030635C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C303030745C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C303030695C3030306E5C303030695C3030305C3034305C303030625C303030615C303030745C303030635C303030685C303030655C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Backpropogration}{10}{section.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Forward Propagation}{10}{subsection.1.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Backward Propagation}{10}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Update Rule}{10}{subsection.1.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Stochastic Gradient Descent and Mini batches}{10}{section.1.9}\protected@file@percent }
\BKM@entry{id=19,open,dest={73656374696F6E2E312E3130},srcline={366}}{5C3337365C3337375C303030315C3030302E5C303030315C303030305C3030305C3034305C303030435C303030615C303030705C303030615C303030635C303030695C303030745C303030795C3030302C5C3030305C3034305C3030304F5C303030765C303030655C303030725C303030665C303030695C303030745C303030745C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030555C3030306E5C303030645C303030655C303030725C303030665C303030695C303030745C303030745C303030695C3030306E5C30303067}
\BKM@entry{id=20,open,dest={73656374696F6E2E312E3131},srcline={384}}{5C3337365C3337375C303030315C3030302E5C303030315C303030315C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {1.10}Capacity, Overfitting and Underfitting}{11}{section.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.11}Regularization}{11}{section.1.11}\protected@file@percent }
\BKM@entry{id=21,open,dest={636861707465722E32},srcline={392}}{5C3337365C3337375C303030325C3030305C3034305C303030445C303030655C303030765C303030655C3030306C5C3030306F5C303030705C3030306D5C303030655C3030306E5C303030745C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\BKM@entry{id=22,open,dest={73656374696F6E2E322E31},srcline={394}}{5C3337365C3337375C303030325C3030302E5C303030315C3030305C3034305C303030535C3030306F5C303030665C303030745C3030306D5C303030615C303030785C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304E5C303030655C303030675C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030304C5C3030306F5C303030675C3030305C3034305C3030304C5C303030695C3030306B5C303030655C3030306C5C303030695C303030685C3030306F5C3030306F5C30303064}
\BKM@entry{id=23,open,dest={73756273656374696F6E2E322E312E31},srcline={401}}{5C3337365C3337375C303030325C3030302E5C303030315C3030302E5C303030315C3030305C3034305C303030535C3030306F5C303030665C303030745C3030306D5C303030615C30303078}
\BKM@entry{id=24,open,dest={73756273656374696F6E2E322E312E32},srcline={421}}{5C3337365C3337375C303030325C3030302E5C303030315C3030302E5C303030325C3030305C3034305C3030304E5C303030655C303030675C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030304C5C3030306F5C303030675C3030305C3034305C3030304C5C303030695C3030306B5C303030655C3030306C5C303030695C303030685C3030306F5C3030306F5C30303064}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Developments in Deep Learning}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Softmax and Negative Log Likelihood}{13}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Softmax}{13}{subsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Softmax Computation for three classes}}{14}{figure.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Negative Log Likelihood}{14}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The loss function reaches infinity when input is 0, and reaches 0 when input is 1.}}{14}{figure.2.2}\protected@file@percent }
\BKM@entry{id=25,open,dest={73756273656374696F6E2E322E312E33},srcline={447}}{5C3337365C3337375C303030325C3030302E5C303030315C3030302E5C303030335C3030305C3034305C303030445C303030655C303030725C303030695C303030765C303030615C303030745C303030695C303030765C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030535C3030306F5C303030665C303030745C3030306D5C303030615C30303078}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces When computing the loss, we can then see that higher confidence at the correct class leads to lower loss and vice-versa.}}{15}{figure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Derivative of the Softmax}{15}{subsection.2.1.3}\protected@file@percent }
\BKM@entry{id=26,open,dest={73656374696F6E2E322E32},srcline={479}}{5C3337365C3337375C303030325C3030302E5C303030325C3030305C3034305C303030485C303030695C303030645C303030645C303030655C3030306E5C3030305C3034305C303030555C3030306E5C303030695C303030745C30303073}
\BKM@entry{id=27,open,dest={73656374696F6E2E322E33},srcline={501}}{5C3337365C3337375C303030325C3030302E5C303030335C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C303030655C3030305C3034305C303030445C303030655C303030735C303030695C303030675C3030306E5C3030303A5C3030305C3034305C3030304B5C303030655C303030795C3030305C3034305C303030435C3030306F5C3030306E5C303030735C303030695C303030645C303030655C303030725C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Hidden Units}{16}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Architecture Design: Key Considerations}{16}{section.2.3}\protected@file@percent }
\BKM@entry{id=28,open,dest={73656374696F6E2E322E34},srcline={516}}{5C3337365C3337375C303030325C3030302E5C303030345C3030305C3034305C303030555C3030306E5C303030695C303030765C303030655C303030725C303030735C303030615C3030306C5C3030305C3034305C303030415C303030705C303030705C303030725C3030306F5C303030785C303030695C3030306D5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030545C303030685C303030655C3030306F5C303030725C303030655C3030306D}
\BKM@entry{id=29,open,dest={73656374696F6E2E322E35},srcline={526}}{5C3337365C3337375C303030325C3030302E5C303030355C3030305C3034305C303030425C303030655C303030795C3030306F5C3030306E5C303030645C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030445C303030655C303030735C303030635C303030655C3030306E5C30303074}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Universal Approximation Theorem}{17}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Beyond Gradient Descent}{17}{section.2.5}\protected@file@percent }
\BKM@entry{id=30,open,dest={73756273656374696F6E2E322E352E31},srcline={567}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030315C3030305C3034305C3030304D5C3030306F5C3030306D5C303030655C3030306E5C303030745C303030755C3030306D5C3030305C3034305C303030425C303030615C303030735C303030655C303030645C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Momentum Based Optimization}{18}{subsection.2.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Typical example of a univariate non-convex function $f(x) = x^4 + 4x^3$}}{19}{figure.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Momentum Demonstration at https://distill.pub/2017/momentum/}}{19}{figure.2.5}\protected@file@percent }
\BKM@entry{id=31,open,dest={73756273656374696F6E2E322E352E32},srcline={606}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030325C3030305C3034305C3030304E5C303030655C303030735C303030745C303030725C3030306F5C303030765C3030305C3034305C303030415C303030635C303030635C303030655C3030306C5C303030655C303030725C303030615C303030745C303030655C303030645C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Nestrov Accelerated Gradient Optimization}{20}{subsection.2.5.2}\protected@file@percent }
\BKM@entry{id=32,open,dest={73756273656374696F6E2E322E352E33},srcline={636}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030335C3030305C3034305C303030415C303030645C303030615C303030475C303030725C303030615C303030645C3030305C3034305C3030305C3035305C303030415C303030645C303030615C303030705C303030745C303030695C303030765C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030415C3030306C5C303030675C3030306F5C303030725C303030695C303030745C303030685C3030306D5C3030305C303531}
\BKM@entry{id=33,open,dest={73756273656374696F6E2E322E352E34},srcline={670}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030345C3030305C3034305C303030415C303030645C303030615C303030445C303030655C3030306C5C303030745C30303061}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}AdaGrad (Adaptive Gradient Algorithm)}{21}{subsection.2.5.3}\protected@file@percent }
\BKM@entry{id=34,open,dest={73756273656374696F6E2E322E352E35},srcline={699}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030355C3030305C3034305C303030415C303030645C303030615C3030306D}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}AdaDelta}{22}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Adam}{22}{subsection.2.5.5}\protected@file@percent }
\BKM@entry{id=35,open,dest={73756273656374696F6E2E322E352E36},srcline={732}}{5C3337365C3337375C303030325C3030302E5C303030355C3030302E5C303030365C3030305C3034305C3030304E5C303030415C303030445C303030415C3030304D}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}NADAM}{23}{subsection.2.5.6}\protected@file@percent }
\BKM@entry{id=36,open,dest={73656374696F6E2E322E36},srcline={770}}{5C3337365C3337375C303030325C3030302E5C303030365C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A comparison of various gradient optimizers}}{24}{figure.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Comparision of loss for models with different optimizers}}{24}{figure.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Regularization}{24}{section.2.6}\protected@file@percent }
\BKM@entry{id=37,open,dest={73756273656374696F6E2E322E362E31},srcline={814}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030315C3030305C3034305C3030304C5C303030325C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=38,open,dest={73756273656374696F6E2E322E362E32},srcline={844}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030325C3030305C3034305C3030304C5C303030315C3030305C3034305C303030525C303030655C303030675C303030755C3030306C5C303030615C303030725C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}L2 Regularization}{26}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}L1 Regularization}{26}{subsection.2.6.2}\protected@file@percent }
\BKM@entry{id=39,open,dest={73756273656374696F6E2E322E362E33},srcline={877}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030335C3030305C3034305C3030304E5C3030306F5C303030695C303030735C303030655C3030305C3034305C303030525C3030306F5C303030625C303030755C303030735C303030745C3030306E5C303030655C303030735C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Noise Robustness}{27}{subsection.2.6.3}\protected@file@percent }
\BKM@entry{id=40,open,dest={73756273656374696F6E2E322E362E34},srcline={947}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030345C3030305C3034305C303030455C3030306E5C303030735C303030655C3030306D5C303030625C3030306C5C303030655C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Ensemble Methods}{29}{subsection.2.6.4}\protected@file@percent }
\BKM@entry{id=41,open,dest={73756273656374696F6E2E322E362E35},srcline={982}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030355C3030305C3034305C303030445C303030725C3030306F5C303030705C3030306F5C303030755C30303074}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Dropout}{30}{subsection.2.6.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Dropout Neural Net Model. Left: A standard neural net with 2 hidden layers. Right: An example of a thinned net produced by applying dropout to the network on the left. Crossed units have been dropped.}}{30}{figure.2.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Features learned on MNIST by 256 hidden unit RBMs. The features are ordered by L2 norm.}}{32}{figure.2.9}\protected@file@percent }
\BKM@entry{id=42,open,dest={73756273656374696F6E2E322E362E36},srcline={1028}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030365C3030305C3034305C303030455C303030615C303030725C3030306C5C303030795C3030305C3034305C303030535C303030745C3030306F5C303030705C303030705C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.6}Early Stopping}{33}{subsection.2.6.6}\protected@file@percent }
\BKM@entry{id=43,open,dest={73756273656374696F6E2E322E362E37},srcline={1077}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030375C3030305C3034305C303030445C303030615C303030745C303030615C3030305C3034305C303030415C303030755C303030675C3030306D5C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=44,open,dest={73756273656374696F6E2E322E362E38},srcline={1104}}{5C3337365C3337375C303030325C3030302E5C303030365C3030302E5C303030385C3030305C3034305C303030425C303030615C303030745C303030635C303030685C3030305C3034305C3030304E5C3030306F5C303030725C3030306D5C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.7}Data Augmentation}{34}{subsection.2.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.8}Batch Normalization}{34}{subsection.2.6.8}\protected@file@percent }
\BKM@entry{id=45,open,dest={73656374696F6E2E322E37},srcline={1110}}{5C3337365C3337375C303030325C3030302E5C303030375C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=46,open,dest={73756273656374696F6E2E322E372E31},srcline={1117}}{5C3337365C3337375C303030325C3030302E5C303030375C3030302E5C303030315C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030745C303030615C3030306E5C303030685C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030735C303030695C303030675C3030306D5C3030306F5C303030695C303030645C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=47,open,dest={73756273656374696F6E2E322E372E32},srcline={1130}}{5C3337365C3337375C303030325C3030302E5C303030375C3030302E5C303030325C3030305C3034305C303030575C303030655C303030695C303030675C303030685C303030745C3030305C3034305C303030495C3030306E5C303030695C303030745C303030695C303030615C3030306C5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C303030525C303030655C3030304C5C303030555C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030465C303030755C3030306E5C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Weight Initialization}{35}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Weight Initialization for tanh and sigmoid Activation Functions}{35}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Weight Initialization for ReLU Activation Function}{35}{subsection.2.7.2}\protected@file@percent }
\BKM@entry{id=48,open,dest={636861707465722E33},srcline={1143}}{5C3337365C3337375C303030335C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=49,open,dest={73656374696F6E2E332E31},srcline={1145}}{5C3337365C3337375C303030335C3030302E5C303030315C3030305C3034305C303030505C303030725C303030655C303030765C303030695C3030306F5C303030755C303030735C3030305C3034305C303030445C303030655C303030765C303030655C3030306C5C3030306F5C303030705C3030306D5C303030655C3030306E5C303030745C303030735C3030305C3034305C303030695C3030306E5C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\BKM@entry{id=50,open,dest={73756273656374696F6E2E332E312E31},srcline={1146}}{5C3337365C3337375C303030335C3030302E5C303030315C3030302E5C303030315C3030305C3034305C303030315C303030395C303030355C303030395C3030303A5C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030665C303030695C303030725C303030735C303030745C3030305C3034305C303030645C303030695C303030675C303030695C303030745C303030615C3030306C5C3030305C3034305C303030735C303030635C303030615C3030306E5C3030306E5C303030655C303030725C3030305C3034305C303030775C303030615C303030735C3030305C3034305C303030695C3030306E5C303030765C303030655C3030306E5C303030745C303030655C30303064}
\BKM@entry{id=51,open,dest={73756273656374696F6E2E332E312E32},srcline={1153}}{5C3337365C3337375C303030335C3030302E5C303030315C3030302E5C303030325C3030305C3034305C303030315C303030395C303030365C303030335C3030303A5C3030305C3034305C3030304C5C303030615C303030725C303030725C303030795C3030305C3034305C303030525C3030306F5C303030625C303030655C303030725C303030745C303030735C3030302C5C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030665C303030615C303030745C303030685C303030655C303030725C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030655C303030725C3030305C3034305C303030565C303030695C303030735C303030695C3030306F5C3030306E}
\BKM@entry{id=52,open,dest={73756273656374696F6E2E332E312E33},srcline={1158}}{5C3337365C3337375C303030335C3030302E5C303030315C3030302E5C303030335C3030305C3034305C303030315C303030395C303030365C303030365C3030303A5C3030305C3034305C3030304D5C303030615C303030725C303030765C303030695C3030306E5C3030305C3034305C3030304D5C303030695C3030306E5C303030735C3030306B5C30303079}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Convolutional Neural Networks}{36}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Previous Developments in Computer Vision}{36}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}1959: The first digital scanner was invented}{36}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}1963: Larry Roberts, the father of Computer Vision}{36}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}1966: Marvin Minsky}{36}{subsection.3.1.3}\protected@file@percent }
\BKM@entry{id=53,open,dest={73756273656374696F6E2E332E312E34},srcline={1166}}{5C3337365C3337375C303030335C3030302E5C303030315C3030302E5C303030345C3030305C3034305C303030315C303030395C303030385C303030305C3030303A5C3030305C3034305C3030304E5C303030655C3030306F5C303030635C3030306F5C303030675C3030306E5C303030695C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=54,open,dest={73756273656374696F6E2E332E312E35},srcline={1184}}{5C3337365C3337375C303030335C3030302E5C303030315C3030302E5C303030355C3030305C3034305C303030325C303030305C303030305C303030315C3030303A5C3030305C3034305C303030565C303030695C3030306F5C3030306C5C303030615C3030302D5C3030304A5C3030306F5C3030306E5C303030655C303030735C3030305C3034305C303030465C303030615C303030635C303030655C3030305C3034305C303030445C303030655C303030745C303030655C303030635C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}1980: Neocognition}{37}{subsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Architecture of Neocognition}}{37}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}2001: Viola-Jones Face Detection}{37}{subsection.3.1.5}\protected@file@percent }
\BKM@entry{id=55,open,dest={73656374696F6E2E332E32},srcline={1205}}{5C3337365C3337375C303030335C3030302E5C303030325C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030565C303030615C3030306E5C303030695C3030306C5C3030306C5C303030615C3030305C3034305C303030445C303030655C303030655C303030705C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\BKM@entry{id=56,open,dest={73656374696F6E2E332E33},srcline={1222}}{5C3337365C3337375C303030335C3030302E5C303030335C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030525C3030306F5C3030306C5C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C3030305C3035305C303030435C3030304E5C3030304E5C303030735C3030305C303531}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Limitations of Vanilla Deep Neural Networks}{38}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}The Role of Convolutional Neural Networks (CNNs)}{38}{section.3.3}\protected@file@percent }
\BKM@entry{id=57,open,dest={73656374696F6E2E332E34},srcline={1229}}{5C3337365C3337375C303030335C3030302E5C303030345C3030305C3034305C303030545C303030685C303030655C3030305C3034305C303030435C3030306F5C3030306E5C303030765C3030306F5C3030306C5C303030755C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030304F5C303030705C303030655C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}The Convolution Operation}{39}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An animation of a 2D convolution operation}}{39}{figure.3.2}\protected@file@percent }
\BKM@entry{id=58,open,dest={73756273656374696F6E2E332E342E31},srcline={1272}}{5C3337365C3337375C303030335C3030302E5C303030345C3030302E5C303030315C3030305C3034305C303030535C303030705C303030615C303030725C303030735C303030655C3030305C3034305C303030495C3030306E5C303030745C303030655C303030725C303030615C303030635C303030745C303030695C3030306F5C3030306E5C30303073}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces An example of 2-D convolution without kernel-ﬂipping. In this case we restrict the output to only positions where the kernel lies entirely within the image, called “valid” convolution in some contexts. We draw boxes with arrows to indicate how the upper-left element of the output tensor is formed by applying the kernel to the corresponding upper-left region of the input tensor.}}{40}{figure.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Sparse Interactions}{40}{subsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Sparse connectivity, viewed from below: We highlight one input unit, $x_3$ , and also highlight the output units in $s$ that are affected by this unit. (Top) When $s$ is formed by convolution with a kernel of width 3, only three outputs are affected by $x$. (Bottom) When $s$ is formed by matrix multiplication, connectivity is no longer sparse, so all of the outputs are aﬀected by $x_3$.}}{41}{figure.3.4}\protected@file@percent }
\BKM@entry{id=59,open,dest={73756273656374696F6E2E332E342E32},srcline={1320}}{5C3337365C3337375C303030335C3030302E5C303030345C3030302E5C303030325C3030305C3034305C303030505C303030615C303030725C303030615C3030306D5C303030655C303030745C303030655C303030725C3030305C3034305C303030535C303030685C303030615C303030725C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Sparse connectivity, viewed from above: We highlight one output unit, $s_3$ , and also highlight the input units in $x$ that affect this unit. These units are known as the receptive ﬁeld of $s_3$. (Top) When $s$ is formed by convolution with a kernel of width 3, only three inputs affect $s_3$. (Bottom) When $s$ is formed by matrix multiplication, connectivity is no longer sparse, so all of the inputs aﬀect $s_3$.}}{42}{figure.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Parameter Sharing}{42}{subsection.3.4.2}\protected@file@percent }
\BKM@entry{id=60,open,dest={73756273656374696F6E2E332E342E33},srcline={1338}}{5C3337365C3337375C303030335C3030302E5C303030345C3030302E5C303030335C3030305C3034305C303030455C303030715C303030755C303030695C303030765C303030615C303030725C303030695C303030615C3030306E5C303030745C3030305C3034305C303030525C303030655C303030705C303030725C303030655C303030735C303030655C3030306E5C303030745C303030615C303030745C303030695C3030306F5C3030306E5C30303073}
\BKM@entry{id=61,open,dest={73656374696F6E2E332E35},srcline={1345}}{5C3337365C3337375C303030335C3030302E5C303030355C3030305C3034305C303030505C3030306F5C3030306F5C3030306C5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The receptive ﬁeld of the units in the deeper layers of a convolutional network is larger than the receptive ﬁeld of the units in the shallow layers. This effect increases if the network includes architectural features like strided convolution or pooling. This means that even though direct connections in a convolutional net are very sparse, units in the deeper layers can be indirectly connected to all or most of the input image.}}{43}{figure.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Equivariant Representations}{43}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Pooling}{43}{section.3.5}\protected@file@percent }
\BKM@entry{id=62,open,dest={73656374696F6E2E332E36},srcline={1380}}{5C3337365C3337375C303030335C3030302E5C303030365C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C303030655C303030725C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Transfer Learning}{44}{section.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Max p ooling introduces invariance. (Top) A view of the middle of the output of a convolutional layer. The b ottom row shows outputs of the nonlinearity. The top row shows the outputs of max po oling, with a stride of one pixel b etween p o oling regions and a p ooling region width of three pixels. A view of the same network, after (Bottom) the input has b een shifted to the right by one pixel. Every value in the b ottom row has changed, but only half of the values in the top row have changed, b ecause the max p ooling units are only sensitive to the maximum value in the neighborho od, not its exact location.}}{45}{figure.3.7}\protected@file@percent }
\BKM@entry{id=63,open,dest={73756273656374696F6E2E332E362E31},srcline={1421}}{5C3337365C3337375C303030335C3030302E5C303030365C3030302E5C303030315C3030305C3034305C303030415C3030306C5C303030655C303030785C3030304E5C303030655C30303074}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Example of learned invariances: A pooling unit that pools over multiple features that are learned with separate parameters can learn to be invariant to transformations of the input. Here we show how a set of three learned filters and a max p ooling unit can learn to become invariant to rotation. All three filters are intended to detect a hand-written 5. Each filter attempts to match a slightly different orientation of the 5. When a 5 app ears in the input, the corresponding filter will match it and cause a large activation in a detector unit.}}{46}{figure.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}AlexNet}{46}{subsection.3.6.1}\protected@file@percent }
\BKM@entry{id=64,open,dest={73756273656374696F6E2E332E362E32},srcline={1438}}{5C3337365C3337375C303030335C3030302E5C303030365C3030302E5C303030325C3030305C3034305C3030305A5C303030465C3030304E5C303030655C30303074}
\BKM@entry{id=65,open,dest={73756273656374696F6E2E332E362E33},srcline={1451}}{5C3337365C3337375C303030335C3030302E5C303030365C3030302E5C303030335C3030305C3034305C303030565C303030475C303030475C3030304E5C303030655C30303074}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Architecture of AlexNet}}{47}{figure.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}ZFNet}{47}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}VGGNet}{47}{subsection.3.6.3}\protected@file@percent }
\BKM@entry{id=66,open,dest={73756273656374696F6E2E332E362E34},srcline={1467}}{5C3337365C3337375C303030335C3030302E5C303030365C3030302E5C303030345C3030305C3034305C303030475C3030306F5C3030306F5C303030675C3030306C5C303030655C3030304E5C303030655C303030745C3030305C3034305C3030305C3035305C303030505C303030725C303030655C303030765C303030695C3030306F5C303030755C303030735C3030306C5C303030795C3030305C3034305C303030495C3030306E5C303030635C303030655C303030705C303030745C303030695C3030306F5C3030306E5C3030305C303531}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Architecture of ZFNet}}{48}{figure.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Architecture of VGGNet}}{48}{figure.3.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}GoogleNet (Previously Inception)}{48}{subsection.3.6.4}\protected@file@percent }
\BKM@entry{id=67,open,dest={73756273656374696F6E2E332E362E35},srcline={1493}}{5C3337365C3337375C303030335C3030302E5C303030365C3030302E5C303030355C3030305C3034305C303030525C303030655C303030735C3030304E5C303030655C30303074}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Inception module}}{49}{figure.3.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces GoogleNet Architecture}}{49}{figure.3.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}ResNet}{49}{subsection.3.6.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces ResNet Architecture}}{50}{figure.3.14}\protected@file@percent }
\BKM@entry{id=68,open,dest={636861707465722E34},srcline={1528}}{5C3337365C3337375C303030345C3030305C3034305C303030525C303030655C303030635C303030755C303030725C303030725C303030655C3030306E5C303030745C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030302C5C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030655C303030725C303030735C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=69,open,dest={73656374696F6E2E342E31},srcline={1530}}{5C3337365C3337375C303030345C3030302E5C303030315C3030305C3034305C303030535C303030655C303030715C303030755C303030655C3030306E5C303030745C303030695C303030615C3030306C5C3030305C3034305C303030445C303030615C303030745C30303061}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Recurrent Neural Networks, Transformers and Attention}{51}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Sequential Data}{51}{section.4.1}\protected@file@percent }
\BKM@entry{id=70,open,dest={73656374696F6E2E342E32},srcline={1568}}{5C3337365C3337375C303030345C3030302E5C303030325C3030305C3034305C303030535C303030655C303030715C303030755C303030655C3030306E5C303030635C303030655C3030305C3034305C3030304D5C3030306F5C303030645C303030655C3030306C5C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Different mappings between inputs and outputs in sequence modelling}}{52}{figure.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Sequence Modeling}{52}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces A general architecture of 1D CNN based text classification}}{52}{figure.4.2}\protected@file@percent }
\BKM@entry{id=71,open,dest={73656374696F6E2E342E33},srcline={1584}}{5C3337365C3337375C303030345C3030302E5C303030335C3030305C3034305C303030525C303030655C303030635C303030755C303030725C303030725C303030655C3030306E5C303030745C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Recurrent Neural Networks}{53}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Unfolding graph of an RNN. Each node represents the state at some timet and the function $f$ maps the state at $t$ to the state at $t + 1$. The same parameters (the same value of used to parametrize) are used for all time steps.}}{53}{figure.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A recurrent network with no outputs. This recurrent network just processes information from the input $x$ by incorporating it into the state $h$ that is passed forward through time. (Left) Circuit diagram. The black square indicates a delay of a single time step. The same network seen as an unfolded computational graph, where each (Right) node is now associated with one particular time instance.}}{54}{figure.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Recurrent networks that produce an output at each time step and have recurrent connections between hidden units}}{54}{figure.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Recurrent networks that produce an output at each time step and have recurrent connections only from the output at one time step to the hidden units at the next time step,}}{55}{figure.4.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Recurrent networks with recurrent connections between hidden units, that read an entire sequence and then produce a single output}}{55}{figure.4.7}\protected@file@percent }
\BKM@entry{id=72,open,dest={73656374696F6E2E342E34},srcline={1672}}{5C3337365C3337375C303030345C3030302E5C303030345C3030305C3034305C303030525C3030304E5C3030304E5C3030305C3034305C303030665C303030725C3030306F5C3030306D5C3030305C3034305C303030735C303030635C303030725C303030615C303030745C303030635C30303068}
\BKM@entry{id=73,open,dest={73656374696F6E2E342E35},srcline={1719}}{5C3337365C3337375C303030345C3030302E5C303030355C3030305C3034305C303030545C303030655C303030615C303030635C303030685C303030655C303030725C3030305C3034305C303030465C3030306F5C303030725C303030635C303030695C3030306E5C303030675C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B5C303030735C3030305C3034305C303030775C303030695C303030745C303030685C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030525C303030655C303030665C303030655C303030725C303030655C3030306E5C303030635C30303065}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}RNN from scratch}{56}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Teacher Forcing and Networks with Output Reference}{57}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Time-unfolded recurrent neural network with a single output at the end of the sequence. Such a network can be used to summarize a sequence and produce a fixed-size representation used as input for further processing. There might be a target right at the end (as depicted here) or the gradient on the output $o^{(t)}$ can be obtained by back-propagating from further downstream modules.}}{57}{figure.4.8}\protected@file@percent }
\BKM@entry{id=74,open,dest={73756273656374696F6E2E342E352E31},srcline={1766}}{5C3337365C3337375C303030345C3030302E5C303030355C3030302E5C303030315C3030305C3034305C303030505C303030725C3030306F5C303030665C303030655C303030735C303030735C3030306F5C303030725C3030305C3034305C303030465C3030306F5C303030725C303030635C303030695C3030306E5C30303067}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Illustration of teacher forcing. Teacher forcing is a training technique that is applicable to RNNs that have connections from their output to their hidden states at the next time step. (Left)At train time, we feed the correct output $y^{(t)}$ drawn from the train set as input to $h^{(t+1)}$.(Right)When the model is deployed, the true output is generally not known. In this case, we approximate the correct output $y^{(t)}$ with the model’s output $o^{(t)}$, and feed the output back into the model.}}{58}{figure.4.9}\protected@file@percent }
\BKM@entry{id=75,open,dest={73656374696F6E2E342E36},srcline={1793}}{5C3337365C3337375C303030345C3030302E5C303030365C3030305C3034305C303030525C303030655C303030705C303030725C303030655C303030735C303030655C3030306E5C303030745C303030695C3030306E5C303030675C3030305C3034305C3030306C5C303030615C3030306E5C303030675C303030755C303030615C303030675C303030655C3030305C3034305C303030745C3030306F5C3030305C3034305C303030615C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Professor Forcing}{59}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Representing language to a Neural Network}{59}{section.4.6}\protected@file@percent }
\BKM@entry{id=76,open,dest={73656374696F6E2E342E37},srcline={1802}}{5C3337365C3337375C303030345C3030302E5C303030375C3030305C3034305C303030435C3030306F5C3030306D5C303030705C303030755C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030695C3030306E5C3030305C3034305C303030615C3030305C3034305C303030525C303030655C303030635C303030755C303030725C303030725C303030655C3030306E5C303030745C3030305C3034305C3030304E5C303030655C303030755C303030725C303030615C3030306C5C3030305C3034305C3030304E5C303030655C303030745C303030775C3030306F5C303030725C3030306B}
\BKM@entry{id=77,open,dest={73656374696F6E2E342E38},srcline={1826}}{5C3337365C3337375C303030345C3030302E5C303030385C3030305C3034305C303030425C303030695C303030645C303030695C303030725C303030655C303030635C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030525C3030304E5C3030304E5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Computing the Gradient in a Recurrent Neural Network}{60}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Bidirectional RNNs}{61}{section.4.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Computation of a typical bidirectional recurrent neural network, meant to learn to map input sequences $x$ to target sequences $y$, with loss $L^{(t)}$ at each step $t$.}}{61}{figure.4.10}\protected@file@percent }
\BKM@entry{id=78,open,dest={73656374696F6E2E342E39},srcline={1841}}{5C3337365C3337375C303030345C3030302E5C303030395C3030305C3034305C303030455C3030306E5C303030635C3030306F5C303030645C303030655C303030725C3030302D5C303030445C303030655C303030635C3030306F5C303030645C303030655C303030725C3030305C3034305C303030535C303030655C303030715C303030755C303030655C3030306E5C303030635C303030655C3030302D5C303030745C3030306F5C3030302D5C303030535C303030655C303030715C303030755C303030655C3030306E5C303030635C303030655C3030305C3034305C303030415C303030725C303030635C303030685C303030695C303030745C303030655C303030635C303030745C303030755C303030725C30303065}
\BKM@entry{id=79,open,dest={73656374696F6E2E342E3130},srcline={1858}}{5C3337365C3337375C303030345C3030302E5C303030315C303030305C3030305C3034305C3030304C5C303030695C3030306D5C303030695C303030745C303030615C303030745C303030695C3030306F5C3030306E5C303030735C3030305C3034305C3030306F5C303030665C3030305C3034305C303030525C3030304E5C3030304E}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Encoder-Decoder Sequence-to-Sequence Architecture}{62}{section.4.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Example of an enco der-decoder or sequence-to-sequence RNN architecture,for learning to generate an output sequence $(y^{(1)}, \cdots  , y^{n_y})$ given an input sequence $(x^{(1)} ,x^{(2)} ,\cdots  ,x^{n_x})$. It is composed of an encoder RNN that reads the input sequence and a decoder RNN that generates the output sequence (or computes the probability of a given output sequence). The final hidden state of the encoder RNN is used to compute a generally fixed-size context variable $C$ which represents a semantic summary of the input sequence and is given as input to the decoder RNN.}}{62}{figure.4.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.10}Limitations of RNN}{62}{section.4.10}\protected@file@percent }
\BKM@entry{id=80,open,dest={73656374696F6E2E342E3131},srcline={1876}}{5C3337365C3337375C303030345C3030302E5C303030315C303030315C3030305C3034305C303030415C3030306C5C3030306C5C303030655C303030765C303030695C303030615C303030745C303030695C3030306E5C303030675C3030305C3034305C303030745C303030685C303030655C3030305C3034305C303030705C303030725C3030306F5C303030625C3030306C5C303030655C3030306D5C3030305C3034305C3030306F5C303030665C3030305C3034305C303030565C303030615C3030306E5C303030695C303030735C303030685C303030695C3030306E5C303030675C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C30303074}
\BKM@entry{id=81,open,dest={73656374696F6E2E342E3132},srcline={1884}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030305C3034305C3030304C5C3030306F5C3030306E5C303030675C3030305C3034305C303030535C303030685C3030306F5C303030725C303030745C3030305C3034305C303030545C303030655C303030725C3030306D5C3030305C3034305C3030304D5C303030655C3030306D5C3030306F5C303030725C303030795C3030305C3034305C3030305C3035305C3030304C5C303030535C303030545C3030304D5C3030305C303531}
\@writefile{toc}{\contentsline {section}{\numberline {4.11}Alleviating the problem of Vanishing Gradient}{63}{section.4.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.12}Long Short Term Memory (LSTM)}{63}{section.4.12}\protected@file@percent }
\BKM@entry{id=82,open,dest={73756273656374696F6E2E342E31322E31},srcline={1899}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030302E5C303030315C3030305C3034305C303030465C3030306F5C303030725C303030675C303030655C303030745C3030305C3034305C303030475C303030615C303030745C30303065}
\BKM@entry{id=83,open,dest={73756273656374696F6E2E342E31322E32},srcline={1906}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030302E5C303030325C3030305C3034305C303030495C3030306E5C303030705C303030755C303030745C3030305C3034305C303030475C303030615C303030745C30303065}
\BKM@entry{id=84,open,dest={73756273656374696F6E2E342E31322E33},srcline={1915}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030302E5C303030335C3030305C3034305C303030435C303030655C3030306C5C3030306C5C3030305C3034305C303030535C303030745C303030615C303030745C30303065}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces The LSTM Cell}}{64}{figure.4.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.1}Forget Gate}{64}{subsection.4.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.2}Input Gate}{64}{subsection.4.12.2}\protected@file@percent }
\BKM@entry{id=85,open,dest={73756273656374696F6E2E342E31322E34},srcline={1928}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030302E5C303030345C3030305C3034305C3030304F5C303030755C303030745C303030705C303030755C303030745C3030305C3034305C303030475C303030615C303030745C30303065}
\BKM@entry{id=86,open,dest={73756273656374696F6E2E342E31322E35},srcline={1935}}{5C3337365C3337375C303030345C3030302E5C303030315C303030325C3030302E5C303030355C3030305C3034305C303030485C303030695C303030645C303030645C303030655C3030306E5C3030305C3034305C303030535C303030745C303030615C303030745C303030655C3030305C3034305C303030555C303030705C303030645C303030615C303030745C30303065}
\BKM@entry{id=87,open,dest={73656374696F6E2E342E3133},srcline={1940}}{5C3337365C3337375C303030345C3030302E5C303030315C303030335C3030305C3034305C303030475C303030615C303030745C303030655C303030645C3030305C3034305C303030525C303030655C303030635C303030755C303030725C303030725C303030655C3030306E5C303030745C3030305C3034305C303030555C3030306E5C303030695C30303074}
\BKM@entry{id=88,open,dest={73756273656374696F6E2E342E31332E31},srcline={1949}}{5C3337365C3337375C303030345C3030302E5C303030315C303030335C3030302E5C303030315C3030305C3034305C303030555C303030705C303030645C303030615C303030745C303030655C3030305C3034305C303030475C303030615C303030745C30303065}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.3}Cell State}{65}{subsection.4.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.4}Output Gate}{65}{subsection.4.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.5}Hidden State Update}{65}{subsection.4.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.13}Gated Recurrent Unit}{65}{section.4.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces The GRU Cell}}{65}{figure.4.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.1}Update Gate}{65}{subsection.4.13.1}\protected@file@percent }
\BKM@entry{id=89,open,dest={73756273656374696F6E2E342E31332E32},srcline={1958}}{5C3337365C3337375C303030345C3030302E5C303030315C303030335C3030302E5C303030325C3030305C3034305C303030525C303030655C303030735C303030655C303030745C3030305C3034305C303030475C303030615C303030745C30303065}
\BKM@entry{id=90,open,dest={73756273656374696F6E2E342E31332E33},srcline={1967}}{5C3337365C3337375C303030345C3030302E5C303030315C303030335C3030302E5C303030335C3030305C3034305C303030435C303030615C3030306E5C303030645C303030695C303030645C303030615C303030745C303030655C3030305C3034305C303030485C303030695C303030645C303030645C303030655C3030306E5C3030305C3034305C303030535C303030745C303030615C303030745C30303065}
\BKM@entry{id=91,open,dest={73756273656374696F6E2E342E31332E34},srcline={1972}}{5C3337365C3337375C303030345C3030302E5C303030315C303030335C3030302E5C303030345C3030305C3034305C303030485C303030695C303030645C303030645C303030655C3030306E5C3030305C3034305C303030535C303030745C303030615C303030745C303030655C3030305C3034305C303030555C303030705C303030645C303030615C303030745C30303065}
\BKM@entry{id=92,open,dest={73656374696F6E2E342E3134},srcline={1977}}{5C3337365C3337375C303030345C3030302E5C303030315C303030345C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030695C3030306E5C303030675C3030305C3034305C303030665C3030306F5C303030725C3030305C3034305C3030304C5C3030306F5C3030306E5C303030675C3030302D5C303030545C303030655C303030725C3030306D5C3030305C3034305C303030445C303030655C303030705C303030655C3030306E5C303030645C303030655C3030306E5C303030635C303030695C303030655C30303073}
\BKM@entry{id=93,open,dest={73756273656374696F6E2E342E31342E31},srcline={1987}}{5C3337365C3337375C303030345C3030302E5C303030315C303030345C3030302E5C303030315C3030305C3034305C303030535C303030655C303030635C3030306F5C3030306E5C303030645C3030302D5C3030304F5C303030725C303030645C303030655C303030725C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.2}Reset Gate}{66}{subsection.4.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.3}Candidate Hidden State}{66}{subsection.4.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.4}Hidden State Update}{66}{subsection.4.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.14}Optimizing for Long-Term Dependencies}{66}{section.4.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.1}Second-Order Optimization}{66}{subsection.4.14.1}\protected@file@percent }
\BKM@entry{id=94,open,dest={73756273656374696F6E2E342E31342E32},srcline={2011}}{5C3337365C3337375C303030345C3030302E5C303030315C303030345C3030302E5C303030325C3030305C3034305C303030475C303030725C303030615C303030645C303030695C303030655C3030306E5C303030745C3030305C3034305C303030435C3030306C5C303030695C303030705C303030705C303030695C3030306E5C30303067}
\BKM@entry{id=95,open,dest={73656374696F6E2E342E3135},srcline={2032}}{5C3337365C3337375C303030345C3030302E5C303030315C303030355C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E5C3030305C3034305C303030695C303030735C3030305C3034305C303030615C3030306C5C3030306C5C3030305C3034305C303030795C3030306F5C303030755C3030305C3034305C3030306E5C303030655C303030655C30303064}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.2}Gradient Clipping}{67}{subsection.4.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.15}Attention is all you need}{67}{section.4.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Transformer model architecture}}{68}{figure.4.14}\protected@file@percent }
\BKM@entry{id=96,open,dest={636861707465722E35},srcline={2045}}{5C3337365C3337375C303030355C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030655C303030725C30303073}
\BKM@entry{id=97,open,dest={73656374696F6E2E352E31},srcline={2046}}{5C3337365C3337375C303030355C3030302E5C303030315C3030305C3034305C3030304D5C3030306F5C303030745C303030695C303030765C303030615C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Transformers}{69}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Motivation}{69}{section.5.1}\protected@file@percent }
\BKM@entry{id=98,open,dest={73656374696F6E2E352E32},srcline={2082}}{5C3337365C3337375C303030355C3030302E5C303030325C3030305C3034305C303030575C3030306F5C303030725C303030645C3030305C3034305C303030455C3030306D5C303030625C303030655C303030645C303030645C303030695C3030306E5C303030675C30303073}
\BKM@entry{id=99,open,dest={73756273656374696F6E2E352E322E31},srcline={2089}}{5C3337365C3337375C303030355C3030302E5C303030325C3030302E5C303030315C3030305C3034305C3030304F5C3030306E5C303030655C3030302D5C303030485C3030306F5C303030745C3030305C3034305C303030565C303030655C303030635C303030745C3030306F5C303030725C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Word Embeddings}{70}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}One-Hot Vectors}{70}{subsection.5.2.1}\protected@file@percent }
\BKM@entry{id=100,open,dest={73756273656374696F6E2E352E322E32},srcline={2102}}{5C3337365C3337375C303030355C3030302E5C303030325C3030302E5C303030325C3030305C3034305C303030435C3030306F5C303030755C3030306E5C303030745C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Count-Based Methods}{71}{subsection.5.2.2}\protected@file@percent }
\BKM@entry{id=101,open,dest={73756273656374696F6E2E352E322E33},srcline={2156}}{5C3337365C3337375C303030355C3030302E5C303030325C3030302E5C303030335C3030305C3034305C303030575C3030306F5C303030725C303030645C303030325C303030565C303030655C303030635C3030303A5C3030305C3034305C303030415C3030305C3034305C303030505C303030725C303030655C303030645C303030695C303030635C303030745C303030695C3030306F5C3030306E5C3030302D5C303030425C303030615C303030735C303030655C303030645C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C30303064}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Animation of the topic detection process in a document-word matrix. Every column corresponds to a document, every row to a word. A cell stores the weighting of a word in a document (e.g. by tf-idf), dark cells indicate high weights. LSA groups both documents that contain similar words, as well as words that occur in a similar set of documents. The resulting patterns are used to detect latent components.}}{72}{figure.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Word2Vec: A Prediction-Based Method}{72}{subsection.5.2.3}\protected@file@percent }
\BKM@entry{id=102,open,dest={73656374696F6E2E352E33},srcline={2215}}{5C3337365C3337375C303030355C3030302E5C303030335C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Attention}{74}{section.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Seq-seq model with an input sequence of length 4}}{74}{figure.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces A seq-seq model with an attention layer. Note that the hidden states from each encoder and decoder unit is utilized in the attention layer. Here, the query is from the decoder hidden state, the key and value are from the encoder hidden states (key and value are the same in this figure). The score is the compatibility between the query and key, which can be a dot product between the query and key (or other form of compatibility). The scores then go through the softmax function to yield a set of weights whose sum equals 1. Each weight multiplies its corresponding values to yield the context vector which utilizes all the input hidden states.}}{75}{figure.5.3}\protected@file@percent }
\BKM@entry{id=103,open,dest={73756273656374696F6E2E352E332E31},srcline={2284}}{5C3337365C3337375C303030355C3030302E5C303030335C3030302E5C303030315C3030305C3034305C303030535C303030635C303030615C3030306C5C303030655C303030645C3030305C3034305C303030445C3030306F5C303030745C3030302D5C303030505C303030725C3030306F5C303030645C303030755C303030635C303030745C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Scaled Dot-Product Attention}{76}{subsection.5.3.1}\protected@file@percent }
\BKM@entry{id=104,open,dest={73756273656374696F6E2E352E332E32},srcline={2328}}{5C3337365C3337375C303030355C3030302E5C303030335C3030302E5C303030325C3030305C3034305C3030304D5C303030755C3030306C5C303030745C303030695C3030302D5C303030685C303030655C303030615C303030645C3030305C3034305C303030415C303030745C303030745C303030655C3030306E5C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel.}}{77}{figure.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Multi-head Attention}{77}{subsection.5.3.2}\protected@file@percent }
\BKM@entry{id=105,open,dest={73656374696F6E2E352E34},srcline={2337}}{5C3337365C3337375C303030355C3030302E5C303030345C3030305C3034305C303030545C303030725C303030615C3030306E5C303030735C303030665C3030306F5C303030725C3030306D5C303030655C303030725C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Transformers}{78}{section.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Architecture of the standard transformer. The model comprises encoder and decoder layers, each with stacked self-attention and feed-forward sub-layers. The encoder produces hidden states from an input token sequence, while the decoder generates predictions from an output token sequence and attends to the encoder’s states for input information.}}{78}{figure.5.5}\protected@file@percent }
\ttl@finishall
\gdef \@abspage@last{79}
